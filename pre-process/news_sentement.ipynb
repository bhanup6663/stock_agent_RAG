{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bhanuprakash/Documents/trainings/RAG/pre-\n",
      "[nltk_data]     analysis/nltk/...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/bhanuprakash/Documents/trainings/RAG/pre-\n",
      "[nltk_data]     analysis/nltk/...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/bhanuprakash/Documents/trainings/RAG/pre-\n",
      "[nltk_data]     analysis/nltk/...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set custom NLTK path and download necessary resources\n",
    "nltk.data.path.insert(0, '/Users/bhanuprakash/Documents/trainings/RAG/pre-analysis/nltk/')\n",
    "nltk.download('stopwords', download_dir='/Users/bhanuprakash/Documents/trainings/RAG/pre-analysis/nltk/')\n",
    "nltk.download('punkt', download_dir='/Users/bhanuprakash/Documents/trainings/RAG/pre-analysis/nltk/')\n",
    "nltk.download('wordnet', download_dir='/Users/bhanuprakash/Documents/trainings/RAG/pre-analysis/nltk/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Sentiment Analyzer and load data\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "news_df = pd.read_csv('../../pre-analysis/datasets/yahoo_finance_news1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News Data Sample:\n",
      "  ticker                                              title  \\\n",
      "0    AAL  American Airlines just flew its longest flight...   \n",
      "1    AAL  Zacks.com featured highlights include American...   \n",
      "2    AAL  American Airlines tests boarding technology th...   \n",
      "3    AAL  Is American Airlines Group Inc. (AAL) the Best...   \n",
      "4    AAL  How American Airlines Is Fighting 'Gate Lice' ...   \n",
      "\n",
      "                  publisher  \\\n",
      "0                    Quartz   \n",
      "1                     Zacks   \n",
      "2  Associated Press Finance   \n",
      "3            Insider Monkey   \n",
      "4              Investopedia   \n",
      "\n",
      "                                                link        date  \n",
      "0  https://finance.yahoo.com/m/4b53d028-e5c9-337d...  1730127060  \n",
      "1  https://finance.yahoo.com/news/zacks-com-featu...  1730096760  \n",
      "2  https://finance.yahoo.com/news/american-airlin...  1729960165  \n",
      "3  https://finance.yahoo.com/news/american-airlin...  1729938583  \n",
      "4  https://finance.yahoo.com/m/f9f3b3be-c05f-366b...  1729933200  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3814 entries, 0 to 3813\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ticker     3814 non-null   object\n",
      " 1   title      3814 non-null   object\n",
      " 2   publisher  3814 non-null   object\n",
      " 3   link       3814 non-null   object\n",
      " 4   date       3814 non-null   int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 149.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"News Data Sample:\")\n",
    "print(news_df.head())\n",
    "print(news_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in News Data: ticker       0\n",
      "title        0\n",
      "publisher    0\n",
      "link         0\n",
      "date         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check and handle missing values\n",
    "print(\"\\nMissing values in News Data:\", news_df.isnull().sum())\n",
    "news_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stop words and initialize lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text pre-processing function\n",
    "def clean_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Titles Sample:\n",
      "                                               title  \\\n",
      "0  American Airlines just flew its longest flight...   \n",
      "1  Zacks.com featured highlights include American...   \n",
      "2  American Airlines tests boarding technology th...   \n",
      "3  Is American Airlines Group Inc. (AAL) the Best...   \n",
      "4  How American Airlines Is Fighting 'Gate Lice' ...   \n",
      "\n",
      "                                       cleaned_title  \n",
      "0          american airline flew longest flight ever  \n",
      "1  zackscom featured highlight include american a...  \n",
      "2  american airline test boarding technology audi...  \n",
      "3  american airline group inc aal best airline st...  \n",
      "4  american airline fighting gate louse boarding ...  \n"
     ]
    }
   ],
   "source": [
    "# Clean titles\n",
    "news_df['cleaned_title'] = news_df['title'].apply(clean_text)\n",
    "print(\"\\nCleaned Titles Sample:\")\n",
    "print(news_df[['title', 'cleaned_title']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(text):\n",
    "    sentiment = analyzer.polarity_scores(text)\n",
    "    if sentiment['compound'] >= 0.05:\n",
    "        return 'positive'\n",
    "    elif sentiment['compound'] <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Analysis Sample:\n",
      "                                               title sentiment\n",
      "0  American Airlines just flew its longest flight...   neutral\n",
      "1  Zacks.com featured highlights include American...  positive\n",
      "2  American Airlines tests boarding technology th...  negative\n",
      "3  Is American Airlines Group Inc. (AAL) the Best...  positive\n",
      "4  How American Airlines Is Fighting 'Gate Lice' ...  negative\n"
     ]
    }
   ],
   "source": [
    "# Apply sentiment analysis to cleaned titles\n",
    "news_df['sentiment'] = news_df['cleaned_title'].apply(get_sentiment_score)\n",
    "print(\"\\nSentiment Analysis Sample:\")\n",
    "print(news_df[['title', 'sentiment']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment analysis results saved to ../../pre-analysis/datasets/news_with_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the data with sentiment scores to a new CSV\n",
    "output_path = '../../pre-analysis/datasets/news_with_sentiment.csv'\n",
    "news_df.to_csv(output_path, index=False)\n",
    "print(f\"\\nSentiment analysis results saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
